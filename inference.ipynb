{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import pretty_midi as pyd\n",
    "from arrangement_utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\"Download checkpoints and data at https://we.tl/t-cc2nOC8dAA (379MB) and decompress at the directory\"\"\"\n",
    "DATA_FILE_ROOT = './data_file_dir/'\n",
    "DEVICE = 'cuda:0'\n",
    "piano_arranger, orchestrator, piano_texture, band_prompt = load_premise(DATA_FILE_ROOT, DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize input and preference\n",
    "We provide three sample lead sheets for a quick inference. You should be able to directly run the code blocks after downloading the pre-trained checkpoints.\n",
    "\n",
    "If you wish to test our model on your own lead sheet file, please initialize a sub-folder with its `SONG_NAME` in the `./demo` folder and put the file in, and name the file \"lead sheet.mid\". \n",
    "\n",
    "Please also specify `SEGMENTATION` (phrase structure) and `NOTE_SHIFT` (the duration of the pick-up measure if any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set input lead sheet\"\"\"\n",
    "SONG_NAME, SEGMENTATION, NOTE_SHIFT = 'Castles in the Air', 'A8A8B8B8', 1   #1 beat in the pick-up measure\n",
    "#SONG_NAME, SEGMENTATION, NOTE_SHIFT = 'Jingle Bells', 'A8B8A8', 0\n",
    "#SONG_NAME, SEGMENTATION, NOTE_SHIFT = 'Sally Garden', 'A4A4B4A4', 0\n",
    "\n",
    "\"\"\"Set texture pre-filtering for piano arrangement (default random)\"\"\"\n",
    "RHTHM_DENSITY = np.random.randint(3, 5)\n",
    "VOICE_NUMBER = np.random.randint(3, 5)\n",
    "PREFILTER = (RHTHM_DENSITY, VOICE_NUMBER)\n",
    "\n",
    "\"\"\"Set if use a 2-bar prompt for full-band arrangement (default False)\"\"\" \n",
    "USE_PROMPT = False\n",
    "\n",
    "lead_sheet = read_lead_sheet('./demo', SONG_NAME, SEGMENTATION, NOTE_SHIFT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piano Accompaniment Arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrasal Unit selection begins:\n",
      "\t 4 phrases in the lead sheet;\n",
      "\t set note density filter: (4, 4).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:17<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-harmonization begins ...\n",
      "Piano accompaiment generated!\n"
     ]
    }
   ],
   "source": [
    "midi_piano, acc_piano = piano_arrangement(*lead_sheet, *piano_texture, piano_arranger, PREFILTER)\n",
    "midi_piano.write(f'./demo/{SONG_NAME}/arrangement_piano.mid')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior model initialized with 7 tracks:\n",
      "\t['Acoustic Bass', 'Chromatic Percussion', 'Synth Pad', 'Acoustic Piano', 'Electric Piano', 'Acoustic Bass', 'Acoustic Guitar']\n",
      "Orchestration begins ...\n",
      "Full-band accompaiment generated!\n"
     ]
    }
   ],
   "source": [
    "midi_prompt, func_prompt = prompt_sampling(acc_piano, *band_prompt, DEVICE)\n",
    "if USE_PROMPT:\n",
    "    midi_band = orchestration(acc_piano, None, *func_prompt, orchestrator, DEVICE, blur=.5, p=.1, t=4)\n",
    "else:\n",
    "    instruments, pitch_prompt, time_promt = func_prompt\n",
    "    midi_band = orchestration(acc_piano, None, instruments, None, None, orchestrator, DEVICE, blur=.5, p=.1, t=4)\n",
    "mel_track = pyd.Instrument(program=72, is_drum=False, name='melody')\n",
    "mel_track.notes = midi_piano.instruments[0].notes\n",
    "midi_band.instruments.append(mel_track)\n",
    "midi_band.write(f'./demo/{SONG_NAME}/arrangement_band.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.10_conda11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
